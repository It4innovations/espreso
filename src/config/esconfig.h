
#ifndef ESCONFIG_H_
#define ESCONFIG_H_

#include <cstdlib>
#include <string>
#include <vector>

namespace espreso {

namespace input {
class Description;
}

namespace config {

extern std::vector<input::Description> description;

enum FetiMethod {
	TOTAL_FETI,
	HYBRID_FETI
};

enum B0Type {
	CORNERS,
	KERNELS
};

enum Preconditioner {
	NO_PRECONDITIONER,
	LUMPED,
	WEIGHT,
	DIRICHLET
};

enum Regularization {
	FIX_POINTS,
	NULL_PIVOTS
};

enum CGSolver {
	STANDARD,
	PIPELINED
};

enum KSolver {
	DIRECT_DOUBLE_PRECISION,
	ITERATIVE,
	DIRECT_SINGLE_PRECISION,
	DIRECT_MIXED_PREXISION
};

enum F0Solver {
	KSOLVER_PRECISION = 0,
	DOUBLE_PRECISION = 1
};

enum SAsolver {
	SA_DENSE_on_CPU = 0,
	SA_DENSE_on_ACC = 1,
	SA_SPARSE_on_CPU = 2
};

enum SCPrecision {
	SC_DOUBLE_PRECISION,
	SC_SINGLE_PRECISION
};

enum MatrixType {
	GENERAL,
	SYMMETRIC
};

namespace env {
	extern int MPIrank;
	extern int MPIsize;

	extern size_t MKL_NUM_THREADS;
	extern size_t OMP_NUM_THREADS;
	extern size_t SOLVER_NUM_THREADS;
	extern size_t PAR_NUM_THREADS;
	extern size_t CILK_NWORKERS;

	extern std::string executable;
	extern std::string configurationFile;
};

namespace mesh {
	/// The type of an input problem.
	/**
	 * It specifies the format of an input.
	 * Formats that support only few MPI processes (e.g. Ansys) can be converted
	 * to ESPRESO format by 'decomposer'
	 */
	extern int INPUT;
	enum INPUTalternatives {
		/// Ansys generated by Matsol library
		MATSOL = 1,
		/// Ansys Workbench format
		WORKBENCH = 2,
		/// OpenFOAM format
		OPENFOAM = 3,
		/// ESPRESO binary format
		ESDATA = 4,
		/// ESPRESO internal problem generator
		GENERATOR = 5
	};

	/// A path to an input problem
	/**
	 * A path to an input file in case of Workbench or ESPRESO Problem Generator.
	 * In case of other format, a path to the root director of an input probem.
	 */
	extern std::string PATH;

	/// The number of sub-domains in each cluster.
	/**
	 * The number of sub-domains should be set appropriate to a problem size.
	 * Big sub-domains increase time to solve them. Small sub-domains increase
	 * the size of the coarse problem.
	 *
	 * The shared memory parallelization is mainly through sub-domains. Hence,
	 * the minimal number should be kept higher that the number of threads.
	 */
	extern size_t SUBDOMAINS;

	/// The number of fix points in each sub-domain.
	/**
	 * Fix points are nodes used in the regularization process of stiffness matrix.
	 * It is not recommended to change the default value.
	 */
	extern size_t FIX_POINTS;

	/// The number of selected points on edges and faces.
	/**
	 * TODO: Alex - co presne delaji cornery
	 */
	extern size_t CORNERS;

	/// All vertex points are marked as corner points.
	/**
	 * The 'vertex' is a end point of the 'edge'. If the 'edge' has not any end
	 * ('edge' is a circle), 4 uniformly distributed points are marked.
	 */
	extern bool VERTEX_CORNERS;

	/// Uniformly distributed points on all edges are marked as corner points.
	/**
	 * The 'edges' are border lines of the 'faces'.
	 * The number of corner points on each edge is determined by parameter 'CORNERS'.
	 */
	extern bool EDGE_CORNERS;

	/// Uniformly distributed points on all faces are marked as corner points.
	/**
	 * The 'face' is a common part between two sub-domains.
	 * The number of corner points on each face is determined by parameter 'CORNERS'.
	 */
	extern bool FACE_CORNERS;

	/// Values at the stiffness matrix corresponding to points on ‘edges’ are averaged.
	/**
	 * ESPRESO contains only a premature state of the averaging. Always keep the default value!
	 */
	extern bool AVERAGE_EDGES;

	/// Values at the stiffness matrix corresponding to points on ‘faces’ are averaged.
	/**
	 * ESPRESO contains only a premature state of the averaging. Always keep the default value!
	 */
	extern bool AVERAGE_FACES;
};

namespace output {

	enum Output { VTK, ESDATA }; // only VTK_FULL is working
	extern Output format;

	extern bool saveMesh;
	extern bool saveFixPoints;
	extern bool saveFaces;
	extern bool saveLines;
	extern bool saveCorners;
	extern bool saveDirichlet;
	extern bool saveAveraging;
	extern bool saveResults;

	extern double subdomainShrinkRatio;
	extern double clusterShrinkRatio;

	extern std::vector<input::Description> description;
};

namespace assembler {
	enum Discretization { FEM, BEM, API };
	extern int discretization;

	enum Physics { LinearElasticity, Temperature, TransientElasticity };
	extern int physics;

	extern size_t timeSteps;
};

namespace solver {
	extern double   epsilon;					// Solver requested precision
	extern size_t   maxIterations;				//
	extern size_t   FETI_METHOD;				// 0 - Total FETI; 1 - HFETI;
	extern bool     REDUNDANT_LAGRANGE;
	extern size_t   B0_TYPE;                    // 0 - Corners, 1 - Kernels
	extern bool     USE_SCHUR_COMPLEMENT; 		// 1 - YES
	extern size_t   SCHUR_COMPLEMENT_PREC;		// Schur complement precission - 0 DP; 1 SP
	extern size_t   SCHUR_COMPLEMENT_TYPE;		// 0 - General; 1 - Symmeric
	extern bool 	COMBINE_SC_AND_SPDS;		// Combine usage of SC for Accelerator and Sparse Direct Solver for CPU
	extern bool     KEEP_FACTORS;				// 1 - YES; 0 - NO
	extern size_t   PRECONDITIONER;				// 0 - NO preconditioner; 1 - Lumped
	extern size_t   CG_SOLVER;					// 0 - Standard CG; 1 - Pipelined CG
	extern size_t   REGULARIZATION;				// 0 - from mesh; 1 - from stifness matrix
	extern size_t   KSOLVER;					// 0 - Direct DP, 1 - Iter, 2 - Direct SP, 3 - Direct MIXED Prec
	extern size_t   KSOLVER_SP_iter_steps;		// number of reiteration steps for SP direct solver
	extern double   KSOLVER_SP_iter_norm;
	extern size_t   F0_SOLVER;					// 0 - Direct DP if KSOLVER is DIRECT DP
												// 1 - DIRECT SP if KSOLVER is DIRECT SP
												// 1 - Direct DP if KSOLVER is DIRECT SP
	extern size_t	SA_SOLVER;					// 0 - DENSE on CPU; 1 - DENSE on ACC; 2 - SPARSE on CPU

	extern size_t   N_MICS;
};

namespace info {
	extern std::string output;

	extern size_t verboseLevel;
	extern size_t testingLevel;
	extern size_t measureLevel;

	extern bool printMatrices;
};

}

}


#endif /* ESCONFIG_H_ */
